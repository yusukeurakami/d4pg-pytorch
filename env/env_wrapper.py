import gym
from gym import spaces
import doorenv2
import numpy as np
from dm_env import specs


class EnvWrapper:
    def __init__(self, env_name, env_kwargs=None):
        self.env_name = env_name
        self.env = gym.make(self.env_name, **env_kwargs)

        # true and normalized action spaces
        self._true_action_space = self.env.action_space
        self._norm_action_space = spaces.Box(
            low=-1.0,
            high=1.0,
            shape=self._true_action_space.shape,
            dtype=np.float32
        )

    def reset(self):
        state = self.env.reset()
        return state

    def get_random_action(self):
        action = self.env.action_space.sample()
        return action

    def step(self, action):
        next_state, reward, terminal, _ = self.env.step(action.ravel())
        return next_state, reward, terminal

    def set_random_seed(self, seed):
        self.env.seed(seed)

    def render(self):
        frame = self.env.render(mode='rgb_array')
        return frame

    def close(self):
        self.env.close()

    def get_action_space(self):
        return self.env.action_space

    def normalise_state(self, state):
        return state

    def normalise_reward(self, reward):
        return reward

